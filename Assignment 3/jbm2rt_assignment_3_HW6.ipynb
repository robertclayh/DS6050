{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKjwkWX9f2G"
   },
   "source": [
    "## Module 6 HW (to be submitted with Module 7 HW): From Building Blocks to U-Net - Understanding Architectural Innovation\n",
    "(even if you did the homework with your teammates you should submit individually and include the names of your teammates)\n",
    "\n",
    "### Robert Clay Harris: jbm2rt\n",
    "\n",
    "### Part 1: Understanding U-Net Architecture (15 points)\n",
    "U-Net was introduced by Ronneberger et al. (2015) for biomedical image segmentation. The architecture won the ISBI cell tracking challenge 2015 by a large margin.\n",
    "\n",
    "### Starter Code: Basic U-Net Implementation\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # Input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "```\n",
    "\n",
    "#### Questions to Answer:\n",
    "\n",
    "**Q1.1 (5 points):** Identify and explain the three major architectural components/concepts from our previous lectures that U-Net combines. For each component:\n",
    "\n",
    "- Name the concept\n",
    "\n",
    "Encoder–decoder architecture, skip connections, and fully convolutional design.\n",
    "\n",
    "- Explain how it's implemented in U-Net\n",
    "\n",
    "The encoder path extracts semantic features through convolution and pooling layers, while the decoder path restores spatial resolution using upsampling and convolution. Skip connections concatenate encoder feature maps with decoder maps of the same scale. The model uses only convolutional operations without any fully connected layers.\n",
    "\n",
    "- Describe what problem it solves\n",
    "\n",
    "The encoder–decoder structure enables dense, pixel-wise prediction. Skip connections recover fine spatial detail lost during downsampling. The fully convolutional design reduces parameters, preserves spatial correspondence, and allows variable input sizes.\n",
    "\n",
    "**Q1.2 (5 points):** Skip connections in U-Net use **concatenation** rather than **addition** (as in ResNet).\n",
    "\n",
    "- What are the implications of this design choice?\n",
    "\n",
    "Concatenation keeps encoder and decoder feature maps distinct, allowing the model to learn complex feature combinations and better preserve spatial detail.\n",
    "\n",
    "- How does this affect the number of parameters?\n",
    "  \n",
    "Concatenation doubles the channel dimension at each skip connection, increasing the number of parameters and computational cost.\n",
    "\n",
    "- When might addition be preferred over concatenation?\n",
    "\n",
    "Addition is preferred when encoder and decoder features share the same feature space and dimensionality, such as in residual networks, where efficiency and gradient flow are prioritized.\n",
    "\n",
    "**Q1.3 (5 points):** Critical Analysis:\n",
    "\n",
    "- What are the potential limitations of the original U-Net architecture?\n",
    "  \n",
    "U-Net is computationally expensive, memory-intensive, and prone to overfitting on small datasets. It also lacks global context awareness.\n",
    "\n",
    "- How might U-Net struggle with very high-resolution images?\n",
    "  \n",
    "High-resolution inputs greatly increase memory usage because intermediate feature maps for skip connections must be stored, making training slow or infeasible on limited hardware.\n",
    "\n",
    "- Propose at least two modifications that could address these limitations.\n",
    "  \n",
    "1. Use patch-based training or dilated convolutions to expand receptive fields without high memory cost.\n",
    "2. Incorporate attention mechanisms or lighter encoders (e.g., MobileNet backbone) to reduce parameters and focus computation on relevant regions.\n",
    "\n",
    "---\n",
    "\n",
    "### Part 2: Architectural Variants (15 points)\n",
    "\n",
    "#### Variant 1: U-Net++ (Nested U-Net)\n",
    "\n",
    "U-Net++ introduces nested skip connections to reduce the semantic gap between encoder and decoder features.\n",
    "\n",
    "```python\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net++: A Nested U-Net Architecture\n",
    "    Zhou et al., 2018\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the nested structure\n",
    "        # X^{0,0} -> X^{1,0} -> X^{2,0} -> X^{3,0} -> X^{4,0}\n",
    "        #    |         |         |         |\n",
    "        # X^{0,1} -> X^{1,1} -> X^{2,1} -> X^{3,1}\n",
    "        #    |         |         |\n",
    "        # X^{0,2} -> X^{1,2} -> X^{2,2}\n",
    "        #    |         |\n",
    "        # X^{0,3} -> X^{1,3}\n",
    "        #    |\n",
    "        # X^{0,4}\n",
    "        \n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "        \n",
    "        # Nested skip connections would be implemented here\n",
    "        # This is a simplified structure for illustration\n",
    "        pass\n",
    "```\n",
    "\n",
    "#### Variant 2: V-Net (Volumetric Convolutional Neural Networks)\n",
    "\n",
    "V-Net extends U-Net to 3D volumetric data and adds residual connections within each stage.\n",
    "\n",
    "```python\n",
    "class VNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    V-Net block with residual connection\n",
    "    Milletari et al., 2016\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_convs):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv3d(in_channels if i == 0 else out_channels,\n",
    "                     out_channels, kernel_size=3, padding=1)\n",
    "            for i in range(num_convs)\n",
    "        ])\n",
    "        self.activation = nn.PReLU(out_channels)\n",
    "        \n",
    "        # Residual connection\n",
    "        self.residual = nn.Conv3d(in_channels, out_channels, kernel_size=1) \\\n",
    "                        if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        \n",
    "        out = x\n",
    "        for conv in self.convs:\n",
    "            out = self.activation(conv(out))\n",
    "        \n",
    "        return out + residual\n",
    "```\n",
    "\n",
    "#### Questions to Answer:\n",
    "\n",
    "**Q3.1 (5 points):** U-Net++ Analysis:  \n",
    "\n",
    "- What problem does the nested skip connection architecture solve?\n",
    "\n",
    "It addresses the semantic gap between encoder and decoder feature maps at different depths, where low-level encoder features are less abstract than high-level decoder features.  \n",
    "\n",
    "- How does it reduce the \"semantic gap\"?\n",
    "\n",
    "U-Net++ introduces intermediate convolutional blocks along each skip pathway, gradually refining encoder features before concatenation. This ensures that encoder and decoder features are semantically closer when merged.  \n",
    "\n",
    "- What is the computational cost compared to standard U-Net?\n",
    "\n",
    "The nested structure adds extra convolutional layers and intermediate feature maps, significantly increasing both memory usage and training time compared to the standard U-Net.  \n",
    "\n",
    "---\n",
    "\n",
    "**Q3.2 (5 points):** V-Net Contributions:\n",
    "\n",
    "- Besides 3D extension, what are the key innovations in V-Net?\n",
    "\n",
    "V-Net incorporates residual connections within each convolutional block and replaces traditional cross-entropy loss with a Dice coefficient loss to better handle class imbalance in segmentation.  \n",
    "\n",
    "- Why are residual connections particularly important for volumetric data?\n",
    "\n",
    "Residual connections stabilize gradient flow across deep 3D convolutional layers and help preserve volumetric context, improving convergence and representation of spatial continuity in 3D medical scans. \n",
    "\n",
    "- How does the Dice loss implementation differ for 3D data?\n",
    "\n",
    "For 3D data, Dice loss is computed over volumetric predictions rather than 2D masks, summing voxel-level overlaps between predicted and true segmentations to account for spatial continuity across slices.  \n",
    "\n",
    "---\n",
    "\n",
    "**Q3.3 (5 points):** Comparative Analysis:  \n",
    "\n",
    "| Criterion              | Standard U-Net                        | U-Net++                                       | V-Net                                         |\n",
    "|-------------------------|--------------------------------------|-----------------------------------------------|-----------------------------------------------|\n",
    "| Parameter Count         | Moderate                             | Higher due to nested skip connections          | High due to 3D convolutions and residuals      |\n",
    "| Memory Usage            | Moderate                             | High                                           | Very high (3D feature maps)                   |\n",
    "| Suitable Applications   | 2D biomedical segmentation            | 2D/2.5D biomedical tasks requiring high precision | 3D volumetric medical imaging                 |\n",
    "| Training Difficulty     | Relatively easy                      | Harder due to deeper, nested structure         | Harder due to large memory and compute needs   |\n",
    "| Inference Speed         | Fast                                 | Slower                                         | Slowest                                       |\n",
    "\n",
    "\n",
    "Consider: parameter count, memory usage, suitable applications, training difficulty, and inference speed.\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "### Papers\n",
    "- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)\n",
    "- [UNet++: A Nested U-Net Architecture](https://arxiv.org/abs/1807.10165)\n",
    "- [V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation](https://arxiv.org/abs/1606.04797)\n",
    "\n",
    "### Implementations\n",
    "- [PyTorch U-Net](https://github.com/milesial/Pytorch-UNet)\n",
    "- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)\n",
    "- [MONAI (Medical Imaging)](https://monai.io/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
