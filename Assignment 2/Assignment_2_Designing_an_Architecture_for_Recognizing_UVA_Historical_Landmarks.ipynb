{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qg5u3FdJBsRE"
   },
   "source": [
    "# Recognizing UVA landmarks with neural nets (100 pts)\n",
    "\n",
    "## Robert Clay Harris: jbm2rt\n",
    "\n",
    "The UVA Grounds is known for its Jeffersonian architecture and place in U.S. history as a model for college and university campuses throughout the country.\n",
    "\n",
    "In this assignment, you will attempt the build image recognition systems to classify different buildlings/landmarks on Grounds. You will implement various CNN architectures covered in\n",
    "Chapters 7-8, including VGG blocks, Network-in-Network (NiN) with GAP,\n",
    "Inception modules, and ResNet blocks. You'll also explore transfer learning\n",
    "with pretrained models.\n",
    "\n",
    "Total Points: 100 + 5 bonus points\n",
    "- Part 1: Implement VGG-style blocks (15 pts)\n",
    "- Part 2: Implement NiN with Global Average Pooling (15 pts)\n",
    "- Part 3: Implement Inception modules (15 pts)\n",
    "- Part 4: Implement ResNet blocks (15 pts)\n",
    "- Part 5: Transfer Learning with Pretrained Models (20 pts)\n",
    "- Part 6: Efficient Architectures (20 pts)\n",
    "- Bonus: Achieve >94% accuracy on the test set (5 pts)\n",
    "\n",
    "\n",
    "Dataset: UVA Landmarks with 18 classes\n",
    "\n",
    "To make it easier for you, some codes have been provided to help you process the data, you may modify it to fit your needs. You must submit the .ipynb and pdf files via UVA Canvas with the following format: yourcomputingID_assignment_2.*\n",
    "\n",
    "Best of luck, and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ofO_DoD7s0"
   },
   "source": [
    "# Import Dataset\n",
    "The full dataset is huge (+37GB) with +13K images of 18 classes. So it will take a while to download, extract, and process. To save you time and effort, a subset of the data has been resized and compressed to only 379Mb and stored in a Firebase server. This dataset will be the one you will benchmark for your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Dataset already exists.\n",
      "Training samples: 11428\n",
      "Validation samples: 2858\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset: UVA Landmarks with 18 classes\n",
    "Submission: yourcomputingID_assignment_2.ipynb and pdf\n",
    "\n",
    "IMPORTANT DESIGN PRINCIPLES:\n",
    "1. Use BatchNorm after every Conv layer (before activation)\n",
    "2. Use ReLU activation (inplace=True saves memory)\n",
    "3. Use bias=False in Conv when followed by BatchNorm\n",
    "4. Initialize weights properly for better convergence\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ============================================================================\n",
    "# Data Loading and Preprocessing\n",
    "# ============================================================================\n",
    "\n",
    "def download_dataset():\n",
    "    \"\"\"Download and extract the UVA landmarks dataset.\"\"\"\n",
    "    url = \"https://firebasestorage.googleapis.com/v0/b/uva-landmark-images.appspot.com/o/dataset.zip?alt=media&token=e1403951-30d6-42b8-ba4e-394af1a2ddb7\"\n",
    "\n",
    "    if not os.path.exists('dataset'):\n",
    "        print(\"Downloading dataset...\")\n",
    "        urllib.request.urlretrieve(url, 'dataset.zip')\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        os.remove('dataset.zip')\n",
    "    else:\n",
    "        print(\"Dataset already exists.\")\n",
    "\n",
    "# Download dataset\n",
    "download_dataset()\n",
    "\n",
    "# Dataset parameters\n",
    "data_dir = \"dataset/\"\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "num_classes = 18\n",
    "\n",
    "# Class names for UVA landmarks\n",
    "class_names = ['AcademicalVillage', 'AldermanLibrary', 'AlumniHall', 'AquaticFitnessCenter',\n",
    "               'BavaroHall', 'BrooksHall', 'ClarkHall', 'MadisonHall', 'MinorHall',\n",
    "               'NewCabellHall', 'NewcombHall', 'OldCabellHall', 'OlssonHall', 'RiceHall',\n",
    "               'Rotunda', 'ScottStadium', 'ThorntonHall', 'UniversityChapel']\n",
    "\n",
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "full_dataset = datasets.ImageFolder(data_dir)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Apply transforms\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256, shuffle=False, num_workers=8)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Part 1: VGG-Style Blocks (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG-style block:\n",
    "      - num_convs times: Conv(3x3, bias=False) -> BN -> ReLU\n",
    "      - then MaxPool2d(2, 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_convs=2):\n",
    "        super(VGGBlock, self).__init__()\n",
    "        layers = []\n",
    "        c_in = in_channels\n",
    "        for _ in range(num_convs):\n",
    "            layers += [\n",
    "                nn.Conv2d(c_in, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            c_in = out_channels\n",
    "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified VGG:\n",
    "      stem: 3 -> 64 (Conv-BN-ReLU)\n",
    "      blocks: 64->128, 128->256 (each halving spatial size)\n",
    "      GAP -> Linear(256 -> num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=18):\n",
    "        super(VGGNet, self).__init__()\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        block1 = VGGBlock(64, 128, num_convs=2)\n",
    "        block2 = VGGBlock(128, 256, num_convs=2)\n",
    "\n",
    "        # feature extractor\n",
    "        self.features = nn.Sequential(stem, block1, block2)\n",
    "\n",
    "        # global average pooling and classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)            # conv features\n",
    "        x = self.avgpool(x)             # (B, 256, 1, 1)\n",
    "        x = torch.flatten(x, 1)         # (B, 256)\n",
    "        x = self.classifier(x)          # logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Part 2: Network in Network (NiN) with GAP (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "class NiNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    NiN block:\n",
    "      spatial conv (k=kernel_size, stride, padding)\n",
    "      -> 1x1 conv\n",
    "      -> 1x1 conv\n",
    "    Each conv: Conv (bias=False) -> BN -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(NiNBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    \"\"\"\n",
    "    Network-in-Network with GAP:\n",
    "      NiN(3->96, k=11, s=4) -> MaxPool(3,2)\n",
    "      NiN(96->256, k=5, p=2) -> MaxPool(3,2)\n",
    "      NiN(256->384, k=3, p=1) -> MaxPool(3,2)\n",
    "      NiN(384->num_classes, k=3, p=1)\n",
    "      GAP -> logits (no FC needed)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=18):\n",
    "        super(NiN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            NiNBlock(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            NiNBlock(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            NiNBlock(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            NiNBlock(384, num_classes, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # GAP to 1x1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)     # (B, num_classes, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # (B, num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Part 3: Inception Module (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Inception block with 4 parallel branches:\n",
    "      1) 1x1\n",
    "      2) 1x1 -> 3x3\n",
    "      3) 1x1 -> 5x5\n",
    "      4) 3x3 maxpool -> 1x1\n",
    "    Each conv: Conv(bias=False) -> BN -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool_proj):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "\n",
    "        # Branch 1: 1x1\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch1x1, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(ch1x1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Branch 2: 1x1 -> 3x3\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3_reduce, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(ch3x3_reduce),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch3x3_reduce, ch3x3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ch3x3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Branch 3: 1x1 -> 5x5\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5_reduce, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(ch5x5_reduce),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch5x5_reduce, ch5x5, kernel_size=5, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(ch5x5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Branch 4: 3x3 maxpool (s=1, p=1) -> 1x1\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(pool_proj),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        b4 = self.branch4(x)\n",
    "        return torch.cat([b1, b2, b3, b4], dim=1)\n",
    "\n",
    "\n",
    "class SimpleGoogLeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified GoogLeNet with Inception modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=18):\n",
    "        super(SimpleGoogLeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # Inception3a: input=64, output=256 (64+128+32+32)\n",
    "        self.inception3a = InceptionBlock(64, 64, 96, 128, 16, 32, 32)\n",
    "        # Inception3b: input=256, output=480 (128+192+96+64)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(480, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Part 4: ResNet Blocks (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic ResNet block:\n",
    "      Main: 3x3(s=stride) -> BN -> ReLU -> 3x3 -> BN\n",
    "      Skip: Identity or 1x1(s=stride) -> BN (when shape changes)\n",
    "      Out:  Add -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # main path\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # skip path (projection if shape changes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = out + self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18:\n",
    "      conv1 (7x7,s=2) -> maxpool\n",
    "      layer1: 2x(64)\n",
    "      layer2: 2x(128), downsample\n",
    "      layer3: 2x(256), downsample\n",
    "      layer4: 2x(512), downsample\n",
    "      GAP -> FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=18):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # stem\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # residual stages\n",
    "        self.layer1 = self._make_layer(64, 64,  num_blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, num_blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, num_blocks=2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, num_blocks=2, stride=2)\n",
    "\n",
    "        # head\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        # first block may downsample / change channels\n",
    "        blocks = [BasicBlock(in_channels, out_channels, stride=stride)]\n",
    "        # remaining blocks keep same channels, stride=1\n",
    "        for _ in range(1, num_blocks):\n",
    "            blocks.append(BasicBlock(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)   # 1/4 size\n",
    "        x = self.layer2(x)   # 1/8\n",
    "        x = self.layer3(x)   # 1/16\n",
    "        x = self.layer4(x)   # 1/32\n",
    "        x = self.avgpool(x)  # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Part 5: Transfer Learning (20 points)\n",
    "# ============================================================================\n",
    "\n",
    "def get_pretrained_model(model_name='resnet18', num_classes=18, feature_extract=True):\n",
    "    \"\"\"\n",
    "    Return a pretrained model with its final classifier replaced for `num_classes`.\n",
    "    If `feature_extract` is True, freeze all feature parameters.\n",
    "    Supported: 'resnet18', 'vgg16', 'mobilenet_v2'\n",
    "    \"\"\"\n",
    "    name = model_name.lower()\n",
    "\n",
    "    if name == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        if feature_extract:\n",
    "            for p in model.parameters():\n",
    "                p.requires_grad = False\n",
    "        in_feats = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_feats, num_classes)\n",
    "        return model\n",
    "\n",
    "    elif name == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        if feature_extract:\n",
    "            for p in model.features.parameters():  # freeze conv backbone\n",
    "                p.requires_grad = False\n",
    "        # replace last linear layer\n",
    "        in_feats = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(in_feats, num_classes)\n",
    "        return model\n",
    "\n",
    "    elif name == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        if feature_extract:\n",
    "            for p in model.parameters():\n",
    "                p.requires_grad = False\n",
    "        # replace last linear layer in classifier\n",
    "        in_feats = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_feats, num_classes)\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_name '{model_name}'. \"\n",
    "                         \"Choose from: 'resnet18', 'vgg16', 'mobilenet_v2'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training and Evaluation Functions (Provided - No modifications needed)\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with training history\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 30)\n",
    "\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history['train_loss'], label='Train Loss')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'{title} - Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history['train_acc'], label='Train Acc')\n",
    "    ax2.plot(history['val_acc'], label='Val Acc')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title(f'{title} - Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9R8dgX-4AVnK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing your CNN implementations on UVA Landmarks Dataset\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Part 1: Testing VGGNet\n",
      "============================================================\n",
      "VGGNet Parameters: 1,113,938\n",
      "\n",
      "Epoch 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/90 [00:00<?, ?it/s]/home/jbm2rt/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Training:  58%|█████▊    | 52/90 [04:43<03:27,  5.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m vgg_model = VGGNet(num_classes=num_classes)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVGGNet Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mvgg_model.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m vgg_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mVGGNet\u001b[39m\u001b[33m'\u001b[39m] = vgg_history[\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     25\u001b[39m plot_training_history(vgg_history, \u001b[33m\"\u001b[39m\u001b[33mVGGNet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, lr)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n\u001b[32m     75\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     13\u001b[39m inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     18\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mVGGNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m            \u001b[38;5;66;03m# conv features\u001b[39;00m\n\u001b[32m     55\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.avgpool(x)             \u001b[38;5;66;03m# (B, 256, 1, 1)\u001b[39;00m\n\u001b[32m     56\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)         \u001b[38;5;66;03m# (B, 256)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mVGGBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Main Execution - Test Your Implementations\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing your CNN implementations on UVA Landmarks Dataset\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Test each architecture with fewer epochs for quick validation\n",
    "    test_epochs = 5  # Increase to 20-30 for better results\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Part 1: Test VGGNet\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Part 1: Testing VGGNet\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        vgg_model = VGGNet(num_classes=num_classes)\n",
    "        print(f\"VGGNet Parameters: {sum(p.numel() for p in vgg_model.parameters()):,}\")\n",
    "        vgg_history = train_model(vgg_model, train_loader, val_loader, num_epochs=test_epochs)\n",
    "        results['VGGNet'] = vgg_history['val_acc'][-1]\n",
    "        plot_training_history(vgg_history, \"VGGNet\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in VGGNet: {e}\")\n",
    "        results['VGGNet'] = 0\n",
    "\n",
    "    # Part 2: Test NiN\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Part 2: Testing Network in Network\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        nin_model = NiN(num_classes=num_classes)\n",
    "        print(f\"NiN Parameters: {sum(p.numel() for p in nin_model.parameters()):,}\")\n",
    "        nin_history = train_model(nin_model, train_loader, val_loader, num_epochs=test_epochs)\n",
    "        results['NiN'] = nin_history['val_acc'][-1]\n",
    "        plot_training_history(nin_history, \"NiN\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NiN: {e}\")\n",
    "        results['NiN'] = 0\n",
    "\n",
    "    # Part 3: Test Inception\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Part 3: Testing Inception Module\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        inception_model = SimpleGoogLeNet(num_classes=num_classes)\n",
    "        print(f\"GoogLeNet Parameters: {sum(p.numel() for p in inception_model.parameters()):,}\")\n",
    "        inception_history = train_model(inception_model, train_loader, val_loader, num_epochs=test_epochs)\n",
    "        results['Inception'] = inception_history['val_acc'][-1]\n",
    "        plot_training_history(inception_history, \"Inception\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Inception: {e}\")\n",
    "        results['Inception'] = 0\n",
    "\n",
    "    # Part 4: Test ResNet\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Part 4: Testing ResNet\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        resnet_model = ResNet18(num_classes=num_classes)\n",
    "        print(f\"ResNet18 Parameters: {sum(p.numel() for p in resnet_model.parameters()):,}\")\n",
    "        resnet_history = train_model(resnet_model, train_loader, val_loader, num_epochs=test_epochs)\n",
    "        results['ResNet18'] = resnet_history['val_acc'][-1]\n",
    "        plot_training_history(resnet_history, \"ResNet18\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ResNet: {e}\")\n",
    "        results['ResNet18'] = 0\n",
    "\n",
    "    # Part 5: Test Transfer Learning\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Part 5: Testing Transfer Learning\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Test feature extraction\n",
    "    try:\n",
    "        print(\"\\nTesting Feature Extraction (frozen backbone)...\")\n",
    "        pretrained_frozen = get_pretrained_model('resnet18', num_classes=num_classes, feature_extract=True)\n",
    "        frozen_history = train_model(pretrained_frozen, train_loader, val_loader, num_epochs=test_epochs)\n",
    "        results['Transfer_Frozen'] = frozen_history['val_acc'][-1]\n",
    "        plot_training_history(frozen_history, \"Transfer Learning (Frozen)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Transfer Learning (Frozen): {e}\")\n",
    "        results['Transfer_Frozen'] = 0\n",
    "\n",
    "    # Test fine-tuning\n",
    "    try:\n",
    "        print(\"\\nTesting Fine-tuning (trainable backbone)...\")\n",
    "        pretrained_finetune = get_pretrained_model('resnet18', num_classes=num_classes, feature_extract=False)\n",
    "        finetune_history = train_model(pretrained_finetune, train_loader, val_loader,\n",
    "                                      num_epochs=test_epochs, lr=0.0001)\n",
    "        results['Transfer_Finetune'] = finetune_history['val_acc'][-1]\n",
    "        plot_training_history(finetune_history, \"Transfer Learning (Fine-tune)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Transfer Learning (Fine-tune): {e}\")\n",
    "        results['Transfer_Finetune'] = 0\n",
    "\n",
    "    # Print summary of results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    for model_name, accuracy in results.items():\n",
    "        print(f\"{model_name:20s}: {accuracy:.2f}%\")\n",
    "\n",
    "    best_model = max(results, key=results.get)\n",
    "    best_accuracy = results[best_model]\n",
    "    print(f\"\\nBest Model: {best_model} with {best_accuracy:.2f}% validation accuracy\")\n",
    "\n",
    "    if best_accuracy > 94:\n",
    "        print(\"\\n🎉 BONUS ACHIEVED! Accuracy > 94%\")\n",
    "    else:\n",
    "        print(f\"\\nKeep improving! Current best: {best_accuracy:.2f}% (Target: 94% for bonus)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Assignment Complete!\")\n",
    "    print(\"Remember to submit: yourcomputingID_assignment_2.py\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaKzcWGkHKC3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment Extension: Memory-Efficient Architectures for Edge Deployment\n",
    "========================================================================\n",
    "Learning Objectives:\n",
    "1. Implement depthwise separable convolutions (MobileNet)\n",
    "2. Build inverted residual blocks (MobileNetV2)\n",
    "3. Understand FLOPs vs parameters vs memory trade-offs\n",
    "4. Design models for memory-constrained devices\n",
    "\n",
    "Total Points: 20\n",
    "- Depthwise Separable Conv implementation (5 pts)\n",
    "- Inverted Residual Block implementation (5 pts)\n",
    "- MobileNetV2 architecture (5 pts)\n",
    "- Model efficiency analysis (5 pts)\n",
    "\n",
    "IMPORTANT CONCEPTS:\n",
    "- FLOPs (Floating Point Operations): Measure of computational cost\n",
    "  Standard Conv: FLOPs = 2 × H × W × K² × C_in × C_out\n",
    "  Depthwise Conv: FLOPs = 2 × H × W × K² × C_in\n",
    "  Pointwise Conv: FLOPs = 2 × H × W × C_in × C_out\n",
    "\n",
    "- Parameters: Number of trainable weights\n",
    "  Standard Conv: params = K² × C_in × C_out + C_out (bias)\n",
    "  Depthwise: params = K² × C_in + C_in\n",
    "  Pointwise: params = C_in × C_out + C_out\n",
    "\n",
    "- Memory: Storage needed for model weights (typically 4 bytes per float32 param)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Download dataset function\n",
    "def download_dataset():\n",
    "    \"\"\"Download and extract the UVA landmarks dataset.\"\"\"\n",
    "    url = \"https://firebasestorage.googleapis.com/v0/b/uva-landmark-images.appspot.com/o/dataset.zip?alt=media&token=e1403951-30d6-42b8-ba4e-394af1a2ddb7\"\n",
    "\n",
    "    if not os.path.exists('dataset'):\n",
    "        print(\"Downloading dataset...\")\n",
    "        urllib.request.urlretrieve(url, 'dataset.zip')\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        os.remove('dataset.zip')\n",
    "    else:\n",
    "        print(\"Dataset already exists.\")\n",
    "\n",
    "download_dataset()\n",
    "\n",
    "# Dataset parameters\n",
    "data_dir = \"dataset/\"\n",
    "batch_size = 32\n",
    "img_size = 224  # MobileNet/EfficientNet use 224x224\n",
    "num_classes = 18\n",
    "\n",
    "# Data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "full_dataset = datasets.ImageFolder(data_dir)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataset.dataset.transform = transform_train\n",
    "val_dataset.dataset.transform = transform_val\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Part 1: Depthwise Separable Convolution (5 points)\n",
    "# ============================================================================\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO (5 pts): Implement depthwise separable convolution as used in MobileNet.\n",
    "\n",
    "    This replaces a standard convolution with two operations:\n",
    "    1. Depthwise convolution: Apply a single filter per input channel\n",
    "    2. Pointwise convolution: 1x1 conv to combine channels\n",
    "\n",
    "    Design Requirements:\n",
    "    - Depthwise: Conv2d with groups=in_channels (each filter operates on one channel)\n",
    "    - Pointwise: Conv2d with kernel_size=1 (combines information across channels)\n",
    "    - Use BatchNorm2d after each convolution\n",
    "    - Use ReLU6 activation (clamps output between 0 and 6, better for quantization)\n",
    "    - No bias in conv layers when using BatchNorm (bias=False)\n",
    "\n",
    "    Efficiency Analysis:\n",
    "    - Standard 3x3 conv: 9 × C_in × C_out parameters\n",
    "    - Depthwise + Pointwise: 9 × C_in + C_in × C_out parameters\n",
    "    - Reduction factor: approximately 8-9x for typical channel counts\n",
    "\n",
    "    Example: C_in=128, C_out=128\n",
    "    - Standard: 9 × 128 × 128 = 147,456 params\n",
    "    - DW+PW: 9 × 128 + 128 × 128 = 17,536 params (8.4x reduction!)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "\n",
    "        # TODO: Implement depthwise convolution\n",
    "        # Hint: Use groups=in_channels to make each filter operate on single channel\n",
    "        # Structure: Conv2d -> BatchNorm2d -> ReLU6\n",
    "        # Kernel size should be 3x3 with padding=1 to maintain spatial dimensions\n",
    "\n",
    "        # TODO: Implement pointwise convolution\n",
    "        # Hint: This is a 1x1 convolution that combines the depthwise outputs\n",
    "        # Structure: Conv2d(kernel_size=1) -> BatchNorm2d -> ReLU6\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Apply depthwise then pointwise convolution\n",
    "        # Return the final output\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 2: Inverted Residual Block (5 points)\n",
    "# ============================================================================\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO (5 pts): Implement the inverted residual block from MobileNetV2.\n",
    "\n",
    "    Key Innovation: \"Inverted\" means we expand channels first, then compress\n",
    "    Traditional residual: wide -> narrow -> wide\n",
    "    Inverted residual: narrow -> wide -> narrow\n",
    "\n",
    "    Architecture:\n",
    "    1. Expansion layer: 1x1 conv to expand channels by expand_ratio\n",
    "    2. Depthwise layer: 3x3 depthwise conv (may have stride for downsampling)\n",
    "    3. Projection layer: 1x1 conv to project back to output channels\n",
    "    4. Skip connection: Only when stride=1 AND in_channels=out_channels\n",
    "\n",
    "    Design Requirements:\n",
    "    - Expansion: Only if expand_ratio != 1 (skip if no expansion needed)\n",
    "    - All layers use BatchNorm, but NO activation after final projection\n",
    "    - Use ReLU6 for all activations except the last layer\n",
    "    - hidden_dim = in_channels * expand_ratio\n",
    "\n",
    "    Memory Optimization:\n",
    "    - Linear bottleneck (no activation after projection) preserves information\n",
    "    - Skip connection only when dimensions match (saves memory)\n",
    "\n",
    "    FLOP Analysis for one block (H×W×C_in input):\n",
    "    - Expansion: H×W×C_in×(expand_ratio×C_in) FLOPs\n",
    "    - Depthwise: H×W×9×(expand_ratio×C_in) FLOPs\n",
    "    - Projection: H×W×(expand_ratio×C_in)×C_out FLOPs\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expand_ratio=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "\n",
    "        # TODO: Determine when to use residual connection\n",
    "        # Residual only when: stride=1 AND in_channels=out_channels\n",
    "        # Store as self.use_residual\n",
    "\n",
    "        # TODO: Build the layers list\n",
    "        # If expand_ratio != 1:\n",
    "        #   Add expansion layer: Conv2d(kernel=1) -> BN -> ReLU6\n",
    "        # Always add:\n",
    "        #   Depthwise: Conv2d(kernel=3, stride=stride, groups=hidden_dim) -> BN -> ReLU6\n",
    "        #   Projection: Conv2d(kernel=1) -> BN (NO activation here!)\n",
    "\n",
    "        # TODO: Combine layers into self.conv = nn.Sequential(*layers)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        # If self.use_residual is True: return x + self.conv(x)\n",
    "        # Otherwise: return self.conv(x)\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 3: MobileNetV2 Architecture (5 points)\n",
    "# ============================================================================\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO (5 pts): Build a simplified MobileNetV2 architecture.\n",
    "\n",
    "    Architecture Overview:\n",
    "    1. Initial conv: 3 -> 32 channels, stride=2 (downsample to 112x112)\n",
    "    2. Series of InvertedResidual blocks with specific configurations\n",
    "    3. Final conv: expand to 1280 channels (wide feature layer)\n",
    "    4. Global average pooling\n",
    "    5. Classifier: Linear(1280, num_classes)\n",
    "\n",
    "    Block Configuration:\n",
    "    Each block has (in_channels, out_channels, stride, expand_ratio)\n",
    "    - t=1: no expansion, t=6: 6x expansion\n",
    "    - s=2: downsample spatial dimensions by 2\n",
    "\n",
    "    Design Principles:\n",
    "    - Width multiplier: Can scale all channels by a factor (0.5, 0.75, 1.0)\n",
    "    - Resolution multiplier: Can use smaller input sizes (192, 160, 128)\n",
    "\n",
    "    Memory Considerations:\n",
    "    - Peak memory usage occurs at expansion layers\n",
    "    - Skip connections don't add parameters but need memory for gradients\n",
    "    - Total params ≈ 2.3M for width_mult=1.0 (vs ResNet50's 25M)\n",
    "\n",
    "    Suggested Block Sequence (simplified):\n",
    "    Stage 1: 32 -> 16, t=1, s=1\n",
    "    Stage 2: 16 -> 24, t=6, s=2 (downsample)\n",
    "             24 -> 24, t=6, s=1\n",
    "    Stage 3: 24 -> 32, t=6, s=2 (downsample)\n",
    "             32 -> 32, t=6, s=1 (repeat 2x)\n",
    "    Stage 4: 32 -> 64, t=6, s=2 (downsample)\n",
    "             64 -> 64, t=6, s=1 (repeat 3x)\n",
    "    Stage 5: 64 -> 96, t=6, s=1 (repeat 3x)\n",
    "    Stage 6: 96 -> 160, t=6, s=2 (downsample)\n",
    "             160 -> 160, t=6, s=1 (repeat 2x)\n",
    "    Stage 7: 160 -> 320, t=6, s=1\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=18, width_mult=1.0, dropout_prob=0.2):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        # TODO: Build the initial convolution layer\n",
    "        # Conv2d(3, 32, kernel=3, stride=2, padding=1) -> BN -> ReLU6\n",
    "        # This reduces 224x224 to 112x112\n",
    "\n",
    "        # TODO: Build the InvertedResidual blocks\n",
    "        # Create a nn.Sequential with all the blocks following the configuration above\n",
    "        # Remember to apply width_mult to scale channel counts if needed\n",
    "\n",
    "        # TODO: Build the final convolution layer\n",
    "        # Conv2d(320, 1280, kernel=1) -> BN -> ReLU6\n",
    "        # This creates a wide feature layer for better classification\n",
    "\n",
    "        # TODO: Add global average pooling\n",
    "        # Use nn.AdaptiveAvgPool2d((1, 1)) to handle any input size\n",
    "\n",
    "        # TODO: Add dropout for regularization (optional but recommended)\n",
    "        # nn.Dropout(p=dropout_prob) before the classifier\n",
    "\n",
    "        # TODO: Add the final classifier\n",
    "        # nn.Linear(1280, num_classes)\n",
    "\n",
    "        # TODO: Initialize weights properly\n",
    "        # Call self._initialize_weights()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        # Pass through: features -> avgpool -> flatten -> dropout -> classifier\n",
    "        pass\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights for better training.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 4: Model Efficiency Analysis (5 points)\n",
    "# ============================================================================\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and trainable parameters.\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "def get_model_size_mb(model):\n",
    "    \"\"\"Calculate model size in MB (assuming float32 weights).\"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "    return size_all_mb\n",
    "\n",
    "def estimate_flops(model, input_shape=(1, 3, 224, 224)):\n",
    "    \"\"\"\n",
    "    TODO (Bonus): Estimate FLOPs for your model.\n",
    "\n",
    "    Simplified FLOP counting:\n",
    "    - Conv2d: 2 × H_out × W_out × K² × C_in × C_out / groups\n",
    "    - Linear: 2 × in_features × out_features\n",
    "    - BatchNorm: 4 × num_features (can often ignore)\n",
    "\n",
    "    This is complex to implement fully, so a simplified version is fine.\n",
    "    You can also use existing libraries like thop or ptflops if available.\n",
    "    \"\"\"\n",
    "    # Optional implementation\n",
    "    total_flops = 0\n",
    "    # Hint: You'd need to track input/output shapes through the network\n",
    "    return total_flops\n",
    "\n",
    "def measure_inference_time(model, input_shape=(1, 3, 224, 224), num_runs=100):\n",
    "    \"\"\"Measure average inference time in milliseconds.\"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "\n",
    "    # Warm up (important for accurate timing)\n",
    "    for _ in range(10):\n",
    "        with torch.no_grad():\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "    # Synchronize if using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # Time the inference\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end_time = time.time()\n",
    "    avg_time = (end_time - start_time) / num_runs * 1000  # Convert to ms\n",
    "    return avg_time\n",
    "\n",
    "# ============================================================================\n",
    "# Training Functions (Provided - No TODO)\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': running_loss / (progress_bar.n + 1),\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "\n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization Functions (Provided - No TODO)\n",
    "# ============================================================================\n",
    "\n",
    "def plot_model_comparison(models_dict):\n",
    "    \"\"\"Compare efficiency metrics of different models.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    model_names = list(models_dict.keys())\n",
    "    params_list = []\n",
    "    size_list = []\n",
    "    time_list = []\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        total_params, _ = count_parameters(model)\n",
    "        params_list.append(total_params / 1e6)  # Convert to millions\n",
    "        size_list.append(get_model_size_mb(model))\n",
    "        time_list.append(measure_inference_time(model.to(device)))\n",
    "\n",
    "    # Plot 1: Parameters\n",
    "    axes[0, 0].bar(model_names, params_list, color='blue', alpha=0.7)\n",
    "    axes[0, 0].set_ylabel('Parameters (Millions)')\n",
    "    axes[0, 0].set_title('Model Parameters Comparison')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True, axis='y')\n",
    "\n",
    "    # Plot 2: Model Size\n",
    "    axes[0, 1].bar(model_names, size_list, color='green', alpha=0.7)\n",
    "    axes[0, 1].set_ylabel('Size (MB)')\n",
    "    axes[0, 1].set_title('Model Size on Disk')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(True, axis='y')\n",
    "\n",
    "    # Plot 3: Inference Time\n",
    "    axes[1, 0].bar(model_names, time_list, color='red', alpha=0.7)\n",
    "    axes[1, 0].set_ylabel('Time (ms)')\n",
    "    axes[1, 0].set_title('Inference Time (Lower is Better)')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True, axis='y')\n",
    "\n",
    "    # Plot 4: Efficiency Score\n",
    "    axes[1, 1].scatter(params_list, time_list, s=100, alpha=0.7)\n",
    "    for i, name in enumerate(model_names):\n",
    "        axes[1, 1].annotate(name, (params_list[i], time_list[i]),\n",
    "                           fontsize=8, ha='right')\n",
    "    axes[1, 1].set_xlabel('Parameters (Millions)')\n",
    "    axes[1, 1].set_ylabel('Inference Time (ms)')\n",
    "    axes[1, 1].set_title('Efficiency Trade-off (Lower-left is Better)')\n",
    "    axes[1, 1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    \"\"\"Plot training and validation curves.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Loss curves\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Progress - Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Accuracy curves\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training Progress - Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# Main Execution - Test Your Implementation\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Testing Your Efficient Architecture Implementation\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Test your implementations\n",
    "    try:\n",
    "        # Test DepthwiseSeparableConv\n",
    "        print(\"\\n1. Testing DepthwiseSeparableConv...\")\n",
    "        dw_conv = DepthwiseSeparableConv(32, 64)\n",
    "        test_input = torch.randn(1, 32, 56, 56)\n",
    "        output = dw_conv(test_input)\n",
    "        print(f\"   Input shape: {test_input.shape}\")\n",
    "        print(f\"   Output shape: {output.shape}\")\n",
    "        print(f\"   ✓ DepthwiseSeparableConv working!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in DepthwiseSeparableConv: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Test InvertedResidual\n",
    "        print(\"\\n2. Testing InvertedResidual...\")\n",
    "        inv_res = InvertedResidual(32, 32, stride=1, expand_ratio=6)\n",
    "        test_input = torch.randn(1, 32, 56, 56)\n",
    "        output = inv_res(test_input)\n",
    "        print(f\"   Input shape: {test_input.shape}\")\n",
    "        print(f\"   Output shape: {output.shape}\")\n",
    "        print(f\"   ✓ InvertedResidual working!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in InvertedResidual: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Test MobileNetV2\n",
    "        print(\"\\n3. Testing MobileNetV2...\")\n",
    "        mobilenet = MobileNetV2(num_classes=num_classes)\n",
    "        test_input = torch.randn(1, 3, 224, 224)\n",
    "        output = mobilenet(test_input)\n",
    "        print(f\"   Input shape: {test_input.shape}\")\n",
    "        print(f\"   Output shape: {output.shape}\")\n",
    "\n",
    "        # Analyze model\n",
    "        total_params, trainable_params = count_parameters(mobilenet)\n",
    "        model_size = get_model_size_mb(mobilenet)\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"   Model size: {model_size:.2f} MB\")\n",
    "        print(f\"   ✓ MobileNetV2 working!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in MobileNetV2: {e}\")\n",
    "\n",
    "    # Compare with other models\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Model Comparison\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # Create models for comparison\n",
    "        models_to_compare = {\n",
    "            'Your MobileNetV2': MobileNetV2(num_classes=num_classes),\n",
    "            'ResNet18': models.resnet18(num_classes=num_classes),\n",
    "            'Pretrained MobileNetV2': models.mobilenet_v2(weights=None, num_classes=num_classes)\n",
    "        }\n",
    "\n",
    "        # Compare models\n",
    "        for name, model in models_to_compare.items():\n",
    "            total_params, _ = count_parameters(model)\n",
    "            size_mb = get_model_size_mb(model)\n",
    "            print(f\"{name:20s}: {total_params/1e6:.2f}M params, {size_mb:.2f} MB\")\n",
    "\n",
    "        # Visualize comparison\n",
    "        plot_model_comparison(models_to_compare)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model comparison: {e}\")\n",
    "\n",
    "    # Train your model (optional - takes time)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training Your MobileNetV2\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    train_model = input(\"Do you want to train your MobileNetV2? (y/n): \")\n",
    "\n",
    "    if train_model.lower() == 'y':\n",
    "        try:\n",
    "            model = MobileNetV2(num_classes=num_classes, dropout_prob=0.2)\n",
    "            model = model.to(device)\n",
    "\n",
    "            # Setup training\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "            # Training loop\n",
    "            num_epochs = 5\n",
    "            history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "                train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "                val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['val_acc'].append(val_acc)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            # Plot training curves\n",
    "            plot_training_curves(history)\n",
    "\n",
    "            print(f\"\\nFinal Validation Accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "            # Success criteria\n",
    "            if history['val_acc'][-1] > 80:\n",
    "                print(\"✓ Great job! Your model achieves good accuracy while being efficient!\")\n",
    "            elif history['val_acc'][-1] > 70:\n",
    "                print(\"✓ Good start! Try fine-tuning hyperparameters or training longer.\")\n",
    "            else:\n",
    "                print(\"Keep working! Check your implementation and try different settings.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Assignment Complete!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Depthwise separable convolutions reduce parameters by ~8-9x\")\n",
    "    print(\"2. Inverted residuals with linear bottlenecks preserve information\")\n",
    "    print(\"3. MobileNetV2 achieves ResNet-level accuracy with 10x fewer parameters\")\n",
    "    print(\"4. Efficient models are crucial for edge deployment (phones, IoT, etc.)\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
